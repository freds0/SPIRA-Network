{
    "model_name":"conv2d", // spiraconv_v1 and spiraconv_v2
    "seed":42,
    "dataset":{
        "padding_with_max_lenght": true,// if true, the timestep axis will be padded with the longest sequence, else, the timestep will be dynamic and the network will predict a vector of the size of the timestep on the output (if you use convulsions it can decrease)
        "max_seq_len": null, // the data loader set automatically this value and save in train_config['logs_path']/config.json. its is max time dimension value in your train dataset. For convert this value to seconds use: value*hop_length/sample_rate
        // train dataset
        "train_csv":"LibriTTS-gender/metadata_train.csv", // format path_wav, class
        "train_data_root_path": "LibriTTS-gender/", // complementary path for csv
        // evaluation dataset
        "eval_csv":"LibriTTS-gender/metadata_eval.csv", // format path_wav, class
        "eval_data_root_path": "LibriTTS-gender/", // complementary path for csv
        // test dataset
        "test_csv":"LibriTTS-gender/metadata_test.csv", // format path_wav, class
        "test_data_root_path": "LibriTTS-gender/", // complementary path for csv
        // classes definition
        "control_class": 0,
        "patient_class": 1
    },
    "model":{
        "fc1_dim":100,
        "fc2_dim":1
    },
    "train_config": {
        "lr_decay": true, // activate/desactivate Noam Learning Rate Decay Scheme
        "warmup_steps": 1000, //default 4000, Noam decay steps to increase the learning rate from 0 to "lr"
        "epochs": 1000,
        "learning_rate": 1e-3, // Initial learning rate. If Noam decay is active, maximum learning rate.
        "weight_decay": 0.01,  // Weight decay rate for optimizer
        "optimizer":"adam",
        "batch_size": 10,
        "seed": 42,
        "num_workers": 14,
        "logs_path": "./logs/base_model_training/",
        "reinit_layers": null,
        "summary_interval": 100,
        "checkpoint_interval": 1000
    },
    "test_config": {
        "batch_size": 5, // used on evaluation and test
        "num_workers": 10 // used on evaluation and test
    },
    "audio": {
        "feature": "mfcc", // spectrogram or melspectrogram or mfcc
        // wave load paramers
        "sample_rate": 16000,
        "normalize": true, // if true, then output is divided by 1 << 31 (assumes signed 32-bit audio), and normalizes to [-1, 1]. If number, then output is divided by that number If callable, then the output is passed as a parameter to the given function, then the output is divided by the result.

        // mel spectorgram paramers
        "num_mels": 40, // number of mels coefficients
        "mel_fmin": 0.0, // minimum freq level for mel-spec. ~50 for male and ~95 for female voices. Tune for dataset!!
        "mel_fmax": null, // maximum freq level for mel-spec. Tune for dataset!!  good value 8000.0

        // mfcc paramers
        "num_mfcc": 40, // Number of mfc coefficients to retain
        "log_mels": false, //  whether to use log-mel spectrograms instead of db-scaled.

        // general config
        "n_fft": 1200,
        "num_freq": 601,// n_fft//2 + 1
        "hop_length": 160,
        "win_length": 400
    }
}
